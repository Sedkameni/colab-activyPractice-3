{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"15c-pbOJ-uLLt0gmv0wmaC1EJLrf8OAGi","timestamp":1759631944032}],"authorship_tag":"ABX9TyOcwUbxo68A5BO37R8CkU0M"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Part 4: Data Parsing**\n","\n","1 - Develop scripts to parse data files:\n","\n","CSV for survey data:\n","*    Use Python's csv module to read and validate data.\n","*   Check for missing or malformed entries (e.g., empty fields, invalid dates).\n","* Save clean data into a staging table in the database using SQL Bulk Insert\n","\n","JSON for web feedback:\n","  * Use Python's json module to parse nested structures.\n","  * Flatten data and extract fields (e.g., comments, ratings, timestamps).\n","  *  Map JSON keys to database columns and load into the database using SQL scripts.\n","\n","XML for external reviews:\n","  * Use Python's xml.etree.ElementTree library to parse XML structures.\n","  * Validate schema conformity and extract relevant fields.\n","  * **bold text** Convert XML data to rows and load them into relational tables."],"metadata":{"id":"b4oKeBPGl8lt"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hXPSX8Vvl6Z8","executionInfo":{"status":"ok","timestamp":1759633670355,"user_tz":240,"elapsed":144,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"}},"outputId":"8e22514c-dc82-4914-f6e0-7ec1c6dbacc2"},"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","DATA PARSING PIPELINE - ETL Process\n","============================================================\n","=== Parsing CSV: customer_survey.csv ===\n","Processed 3 rows\n","Saved clean data to: customer_survey_clean.csv\n","\n","Found 3 validation issues:\n","  - Row 2: Missing review_id\n","  - Row 3: Missing review_id\n","  - Row 4: Missing review_id\n","\n","=== Parsing JSON: web_feedback.json ===\n","Original columns: ['customer_id', 'rating', 'comments']\n","Processed 3 records\n","Final columns: ['customer_id', 'rating', 'comments', 'customer_email', 'feedback_text', 'sentiment', 'feedback_date']\n","Saved to: web_feedback_clean.csv\n","\n","Sample data:\n","   customer_id  rating                  comments       customer_email  \\\n","0            1       5        Excellent service!  unknown@example.com   \n","1            2       4  Good experience overall.  unknown@example.com   \n","2            3       2            Late delivery.  unknown@example.com   \n","\n","          feedback_text sentiment feedback_date  \n","0  No feedback provided   unknown    2025-10-05  \n","1  No feedback provided   unknown    2025-10-05  \n","2  No feedback provided   unknown    2025-10-05  \n","\n","=== Parsing XML: external_reviews.xml ===\n","Root element: reviews\n","Processed 3 reviews\n","Columns: ['customer_id', 'product_id', 'rating', 'comments', 'review_date']\n","Saved to: external_reviews_clean.csv\n","\n","Sample data:\n","   customer_id  product_id  rating                  comments review_date\n","0            1           1       5        Excellent service!  2025-10-05\n","1            2           1       4  Good experience overall.  2025-10-05\n","2            3           1       2            Late delivery.  2025-10-05\n","\n","============================================================\n","PARSING COMPLETE\n","============================================================\n","\n","Generated files:\n"," customer_survey_clean.csv\n"," web_feedback_clean.csv\n"," external_reviews_clean.csv\n","\n","Next step: Load these files into MySQL using LOAD DATA INFILE\n"]}],"source":["import csv\n","import json\n","import xml.etree.ElementTree as ET\n","import pandas as pd\n","from datetime import datetime\n","import re\n","import os\n","\n","# =====================================================\n","# 1. CSV PARSER - Survey Data with Validation\n","# =====================================================\n","\n","def parse_csv_survey(file_path, output_path='customer_survey_clean.csv'):\n","    \"\"\"\n","    Parse CSV survey data with comprehensive validation\n","    \"\"\"\n","    print(f\"=== Parsing CSV: {file_path} ===\")\n","\n","    clean_data = []\n","    errors = []\n","    row_count = 0\n","\n","    try:\n","        with open(file_path, 'r', encoding='utf-8') as file:\n","            reader = csv.DictReader(file)\n","\n","            for idx, row in enumerate(reader, start=2):  # Start at 2 (1 is header)\n","                row_count += 1\n","                issues = []\n","\n","                # Validate review_id\n","                if not row.get('review_id') or not row['review_id'].strip():\n","                    issues.append(f\"Row {idx}: Missing review_id\")\n","\n","                # Validate name\n","                if not row.get('name') or not row['name'].strip():\n","                    issues.append(f\"Row {idx}: Missing name\")\n","                    row['name'] = 'Unknown'\n","\n","                # Validate email\n","                email = row.get('email', '').strip()\n","                if not email:\n","                    issues.append(f\"Row {idx}: Missing email\")\n","                    row['email'] = f'unknown{idx}@example.com'\n","                elif not re.match(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$', email):\n","                    issues.append(f\"Row {idx}: Invalid email format - {email}\")\n","\n","                # Validate region\n","                if not row.get('region') or not row['region'].strip():\n","                    issues.append(f\"Row {idx}: Missing region\")\n","                    row['region'] = 'Unknown'\n","\n","                # Validate rating\n","                try:\n","                    rating = int(row.get('rating', 0))\n","                    if rating < 1 or rating > 5:\n","                        issues.append(f\"Row {idx}: Rating {rating} out of range (1-5)\")\n","                        row['rating'] = max(1, min(5, rating))  # Clamp to 1-5\n","                except (ValueError, TypeError):\n","                    issues.append(f\"Row {idx}: Invalid rating value\")\n","                    row['rating'] = 3  # Default to middle rating\n","\n","                # Validate comments\n","                if not row.get('comments') or not row['comments'].strip():\n","                    issues.append(f\"Row {idx}: Missing comments\")\n","                    row['comments'] = 'No comment provided'\n","\n","                # Validate and standardize date\n","                date_str = row.get('review_date', '').strip()\n","                standardized_date = validate_and_convert_date(date_str)\n","                if standardized_date:\n","                    row['review_date'] = standardized_date\n","                else:\n","                    issues.append(f\"Row {idx}: Invalid date format - {date_str}\")\n","                    row['review_date'] = datetime.now().strftime('%Y-%m-%d')\n","\n","                # Record issues but keep the row (with corrections)\n","                if issues:\n","                    errors.extend(issues)\n","\n","                clean_data.append(row)\n","\n","        # Save clean data\n","        if clean_data:\n","            df = pd.DataFrame(clean_data)\n","            df.to_csv(output_path, index=False)\n","            print(f\"Processed {row_count} rows\")\n","            print(f\"Saved clean data to: {output_path}\")\n","\n","        # Report errors\n","        if errors:\n","            print(f\"\\nFound {len(errors)} validation issues:\")\n","            for error in errors[:10]:  # Show first 10 errors\n","                print(f\"  - {error}\")\n","            if len(errors) > 10:\n","                print(f\"  ... and {len(errors) - 10} more issues\")\n","\n","        return df, errors\n","\n","    except FileNotFoundError:\n","        print(f\"Error: File not found - {file_path}\")\n","        return None, [f\"File not found: {file_path}\"]\n","    except Exception as e:\n","        print(f\"Error parsing CSV: {str(e)}\")\n","        return None, [str(e)]\n","\n","\n","# =====================================================\n","# 2. JSON PARSER - Web Feedback with Nested Structures\n","# =====================================================\n","\n","def parse_json_feedback(file_path, output_path='web_feedback_clean.csv'):\n","    \"\"\"\n","    Parse JSON web feedback with flattening and validation\n","    \"\"\"\n","    print(f\"\\n=== Parsing JSON: {file_path} ===\")\n","\n","    try:\n","        with open(file_path, 'r', encoding='utf-8') as file:\n","            data = json.load(file)\n","\n","        # Handle different JSON structures\n","        if isinstance(data, dict):\n","            # If JSON is a single object with nested arrays\n","            if 'feedback' in data:\n","                data = data['feedback']\n","            elif 'reviews' in data:\n","                data = data['reviews']\n","\n","        # Flatten nested JSON\n","        df = pd.json_normalize(data)\n","\n","        print(f\"Original columns: {list(df.columns)}\")\n","\n","        # Standardize column names\n","        column_mapping = {}\n","        for col in df.columns:\n","            # Handle nested column names (e.g., 'customer.id' -> 'customer_id')\n","            new_col = col.replace('.', '_').lower()\n","            column_mapping[col] = new_col\n","\n","        df.rename(columns=column_mapping, inplace=True)\n","\n","        # Ensure required columns exist\n","        required_columns = {\n","            'customer_id': 0,\n","            'customer_email': 'unknown@example.com',\n","            'feedback_text': 'No feedback provided',\n","            'sentiment': 'unknown',\n","            'rating': 3,\n","            'feedback_date': datetime.now().strftime('%Y-%m-%d')\n","        }\n","\n","        for col, default in required_columns.items():\n","            if col not in df.columns:\n","                # Try to find similar column\n","                similar = [c for c in df.columns if col.split('_')[-1] in c]\n","                if similar:\n","                    df[col] = df[similar[0]]\n","                else:\n","                    df[col] = default\n","\n","        # Validate ratings if present\n","        if 'rating' in df.columns:\n","            df['rating'] = df['rating'].apply(lambda x: validate_rating(x))\n","\n","        # Validate dates if present\n","        if 'feedback_date' in df.columns:\n","            df['feedback_date'] = df['feedback_date'].apply(\n","                lambda x: validate_and_convert_date(str(x)) or datetime.now().strftime('%Y-%m-%d')\n","            )\n","\n","        # Clean text fields\n","        text_columns = ['feedback_text', 'comments']\n","        for col in text_columns:\n","            if col in df.columns:\n","                df[col] = df[col].fillna('No feedback provided')\n","                df[col] = df[col].str.strip()\n","\n","        # Save to CSV\n","        df.to_csv(output_path, index=False)\n","\n","        print(f\"Processed {len(df)} records\")\n","        print(f\"Final columns: {list(df.columns)}\")\n","        print(f\"Saved to: {output_path}\")\n","        print(f\"\\nSample data:\")\n","        print(df.head())\n","\n","        return df\n","\n","    except FileNotFoundError:\n","        print(f\"Error: File not found - {file_path}\")\n","        return None\n","    except json.JSONDecodeError as e:\n","        print(f\"Error: Invalid JSON format - {str(e)}\")\n","        return None\n","    except Exception as e:\n","        print(f\"Error parsing JSON: {str(e)}\")\n","        return None\n","\n","\n","# =====================================================\n","# 3. XML PARSER - External Reviews with Schema Validation\n","# =====================================================\n","\n","def parse_xml_reviews(file_path, output_path='external_reviews_clean.csv'):\n","    \"\"\"\n","    Parse XML external reviews with validation\n","    \"\"\"\n","    print(f\"\\n=== Parsing XML: {file_path} ===\")\n","\n","    try:\n","        tree = ET.parse(file_path)\n","        root = tree.getroot()\n","\n","        print(f\"Root element: {root.tag}\")\n","\n","        data = []\n","        errors = []\n","\n","        # Find all review elements (handle different possible structures)\n","        review_elements = root.findall('.//review') or root.findall('.//item') or root\n","\n","        for idx, review in enumerate(review_elements, start=1):\n","            row = {}\n","            issues = []\n","\n","            # Extract customer_id\n","            customer_id = get_xml_text(review, ['customer_id', 'customerId', 'CustomerID'])\n","            if customer_id:\n","                try:\n","                    row['customer_id'] = int(customer_id)\n","                except ValueError:\n","                    issues.append(f\"Review {idx}: Invalid customer_id - {customer_id}\")\n","                    row['customer_id'] = 0\n","            else:\n","                issues.append(f\"Review {idx}: Missing customer_id\")\n","                row['customer_id'] = 0\n","\n","            # Extract product_id\n","            product_id = get_xml_text(review, ['product_id', 'productId', 'ProductID'])\n","            if product_id:\n","                try:\n","                    row['product_id'] = int(product_id)\n","                except ValueError:\n","                    issues.append(f\"Review {idx}: Invalid product_id - {product_id}\")\n","                    row['product_id'] = 1\n","            else:\n","                row['product_id'] = 1  # Default product\n","\n","            # Extract rating\n","            rating_text = get_xml_text(review, ['rating', 'Rating', 'score'])\n","            try:\n","                rating = int(rating_text) if rating_text else 3\n","                row['rating'] = validate_rating(rating)\n","                if rating != row['rating']:\n","                    issues.append(f\"Review {idx}: Rating {rating} adjusted to {row['rating']}\")\n","            except ValueError:\n","                issues.append(f\"Review {idx}: Invalid rating - {rating_text}\")\n","                row['rating'] = 3\n","\n","            # Extract comments\n","            comments = get_xml_text(review, ['comments', 'comment', 'Comments', 'text'])\n","            row['comments'] = comments if comments else 'No comment provided'\n","\n","            # Extract date\n","            date_text = get_xml_text(review, ['review_date', 'reviewDate', 'date', 'Date'])\n","            row['review_date'] = validate_and_convert_date(date_text) or datetime.now().strftime('%Y-%m-%d')\n","\n","            # Record errors\n","            if issues:\n","                errors.extend(issues)\n","\n","            data.append(row)\n","\n","        # Create DataFrame\n","        df = pd.DataFrame(data)\n","\n","        # Save to CSV\n","        df.to_csv(output_path, index=False)\n","\n","        print(f\"Processed {len(df)} reviews\")\n","        print(f\"Columns: {list(df.columns)}\")\n","        print(f\"Saved to: {output_path}\")\n","\n","        if errors:\n","            print(f\"\\nFound {len(errors)} validation issues:\")\n","            for error in errors[:5]:\n","                print(f\"  - {error}\")\n","\n","        print(f\"\\nSample data:\")\n","        print(df.head())\n","\n","        return df, errors\n","\n","    except FileNotFoundError:\n","        print(f\"Error: File not found - {file_path}\")\n","        return None, [f\"File not found: {file_path}\"]\n","    except ET.ParseError as e:\n","        print(f\"Error: Invalid XML format - {str(e)}\")\n","        return None, [f\"XML Parse Error: {str(e)}\"]\n","    except Exception as e:\n","        print(f\"Error parsing XML: {str(e)}\")\n","        return None, [str(e)]\n","\n","\n","# =====================================================\n","# UTILITY FUNCTIONS\n","# =====================================================\n","\n","def validate_and_convert_date(date_str):\n","    \"\"\"\n","    Try to parse various date formats and return YYYY-MM-DD\n","    \"\"\"\n","    if not date_str or str(date_str).strip() in ['', 'None', 'NULL']:\n","        return None\n","\n","    date_str = str(date_str).strip()\n","\n","    # Common date formats\n","    formats = [\n","        '%Y-%m-%d',\n","        '%d/%m/%Y',\n","        '%m/%d/%Y',\n","        '%Y/%m/%d',\n","        '%d-%m-%Y',\n","        '%m-%d-%Y',\n","        '%Y%m%d',\n","        '%d.%m.%Y',\n","        '%Y.%m.%d'\n","    ]\n","\n","    for fmt in formats:\n","        try:\n","            dt = datetime.strptime(date_str, fmt)\n","            return dt.strftime('%Y-%m-%d')\n","        except ValueError:\n","            continue\n","\n","    return None\n","\n","\n","def validate_rating(rating):\n","    \"\"\"\n","    Ensure rating is between 1 and 5\n","    \"\"\"\n","    try:\n","        rating = int(rating)\n","        return max(1, min(5, rating))\n","    except (ValueError, TypeError):\n","        return 3\n","\n","\n","def get_xml_text(element, tag_names):\n","    \"\"\"\n","    Try multiple tag names to find text in XML element\n","    \"\"\"\n","    for tag in tag_names:\n","        child = element.find(tag)\n","        if child is not None and child.text:\n","            return child.text.strip()\n","    return None\n","\n","\n","# =====================================================\n","# MAIN EXECUTION\n","# =====================================================\n","\n","if __name__ == \"__main__\":\n","    print(\"=\" * 60)\n","    print(\"DATA PARSING PIPELINE - ETL Process\")\n","    print(\"=\" * 60)\n","\n","    # 1. Parse CSV\n","    csv_df, csv_errors = parse_csv_survey('customer_survey.csv')\n","\n","    # 2. Parse JSON\n","    json_df = parse_json_feedback('web_feedback.json')\n","\n","    # 3. Parse XML\n","    xml_df, xml_errors = parse_xml_reviews('external_reviews.xml')\n","\n","    print(\"\\n\" + \"=\" * 60)\n","    print(\"PARSING COMPLETE\")\n","    print(\"=\" * 60)\n","    print(\"\\nGenerated files:\")\n","    print(\" customer_survey_clean.csv\")\n","    print(\" web_feedback_clean.csv\")\n","    print(\" external_reviews_clean.csv\")\n","    print(\"\\nNext step: Load these files into MySQL using LOAD DATA INFILE\")"]},{"cell_type":"markdown","source":["**Part 3: Data Integration**\n","\n","1 - Import data from multiple formats:\n","\n","*   Extract XML data (e.g., 'external_reviews.xml') into structured tables using XML parsing tools.\n"],"metadata":{"id":"fHihJXY-mwEr"}},{"cell_type":"code","source":["import xml.etree.ElementTree as ET\n","import pandas as pd\n","\n","tree = ET.parse(\"external_reviews.xml\")\n","root = tree.getroot()\n","\n","data = []\n","for review in root.findall(\"review\"):\n","    row = {\n","        \"CustomerID\": review.find(\"customer_id\").text,\n","        \"Rating\": review.find(\"rating\").text,\n","        \"Comments\": review.find(\"comments\").text\n","    }\n","    data.append(row)\n","\n","df = pd.DataFrame(data)\n","\n","#Export the parsed XML file to CSV to be able to use it in workbench\n","df.to_csv('external_reviews.csv', index=False)\n","print(df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FMNv_bV_mvrq","executionInfo":{"status":"ok","timestamp":1759633670374,"user_tz":240,"elapsed":3,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"}},"outputId":"2a71fa4c-bb90-4e47-fa27-c96b9c93dd9e"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["  CustomerID Rating                  Comments\n","0          1      5        Excellent service!\n","1          2      4  Good experience overall.\n","2          3      2            Late delivery.\n"]}]}]}
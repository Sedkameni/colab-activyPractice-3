{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":356,"status":"ok","timestamp":1753348699151,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"},"user_tz":240},"id":"mTZ18eyeuWXW"},"outputs":[],"source":["# Import Pandas library\n","import pandas as pd"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1753348932481,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"},"user_tz":240},"id":"f_Shn0fFJ8GQ"},"outputs":[],"source":["### Task 2: Working with Pandas read_html\n","\n","# URL of a webpage with finance data\n","finance_url = 'Using the URL: https://finance.yahoo.com/gainers '"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Hig4fxN7KV4D"},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipython-input-3-2018846782.py:3: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n","  finance_tables = pd.read_html(finance_url)\n"]},{"ename":"ValueError","evalue":"No tables found","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3-2018846782.py\u001b[0m in \u001b[0;36m\u003ccell line: 0\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### 2 - Extract tables from the URL using Pandas read_html() into a DataFrame.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Read HTML tables from the webpage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 3\u001b[0;31m \u001b[0mfinance_tables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinance_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/html.py\u001b[0m in \u001b[0;36mread_html\u001b[0;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links, dtype_backend, storage_options)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         )\n\u001b[1;32m   1239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1240\u001b[0;31m     return _parse(\n\u001b[0m\u001b[1;32m   1241\u001b[0m         \u001b[0mflavor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflavor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m         \u001b[0mio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/html.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m   1001\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mretained\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# for mypy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1003\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mretained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/html.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 983\u001b[0;31m             \u001b[0mtables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_tables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    984\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcaught\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;31m# if `io` is an io-like object, check if it's seekable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/html.py\u001b[0m in \u001b[0;36mparse_tables\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mparsed\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfooter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mtuples\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \"\"\"\n\u001b[0;32m--\u003e 249\u001b[0;31m         \u001b[0mtables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_tables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_thead_tbody_tfoot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtable\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/html.py\u001b[0m in \u001b[0;36m_parse_tables\u001b[0;34m(self, document, match, attrs)\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0mtables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 598\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No tables found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: No tables found"]}],"source":["### 2 - Extract tables from the URL using Pandas read_html() into a DataFrame.\n","# Read HTML tables from the webpage\n","finance_tables = pd.read_html(finance_url)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1753348154846,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"},"user_tz":240},"id":"VoPtXSAWLU7S","outputId":"0f8853e5-50db-4da9-f82b-65fa973c91d7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of tables found: 24\n"]}],"source":["## 3 - Display the number of tables found in the URL.\n","print(\"Number of tables found:\", len(food_tables))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1753348158942,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"},"user_tz":240},"id":"YlnWDXSDL3BL","outputId":"440443ee-5263-4bc4-ed19-8e9b5971a9e2"},"outputs":[{"name":"stdout","output_type":"stream","text":["First table:\n","                                                   0\n","0                                Part of a series on\n","1                                              Meals\n","2                                              Meals\n","3  Suhur Breakfast Second breakfast Elevenses Bru...\n","4                             Components and courses\n","5  Full-course dinner Tasting menu Amuse-bouche H...\n","6                                   Related concepts\n","7  À la carte Banquet Buffet Cuisine list Drink E...\n","8                                                vte\n"]}],"source":["## 4 - Display the first table in the dataframe.\n","print(\"First table:\")\n","print(food_tables[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jzf609p_MDmX"},"outputs":[],"source":["#### Task 3: Working with BeautifulSoup and html5lib parser\n","\n","## 1 - Install Python BeautifulSoup and Requests Library.\n","import requests\n","from bs4 import BeautifulSoup\n","\n","# URL to scrap data from\n","url = 'https://en.wikipedia.org/wiki/Beautiful_Soup_(HTML_parser)'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kX75RQtBMaUO"},"outputs":[],"source":["## 3.2 - Send a GET request to the URL\n","request = requests.get(url)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9iOEHvsiMhiy"},"outputs":[],"source":["### 3.3 - Scrap content using Beautiful and html5lib parser.\n","soup = BeautifulSoup(request.content, 'html5lib')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jzsjmSsxMwvB"},"outputs":[],"source":["#### 3.4 - Find the first paragraph.\n","# Find and extract the first paragraph\n","first_paragraph = soup.find('p')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1753348217601,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"},"user_tz":240},"id":"plRYu2TuNdJB","outputId":"8cbd3357-b395-4f48-dc65-fea962a41400"},"outputs":[{"name":"stdout","output_type":"stream","text":["First paragraph of the article:\n","Beautiful Soup is a Python package for parsing HTML and XML documents, including those with malformed markup. It creates a parse tree for documents that can be used to extract data from HTML,[3] which is useful for web scraping.[2][4]\n"]}],"source":["### 3.5 - Display the first paragraph text.\n","# Print the text of the first paragraph\n","print(\"First paragraph of the article:\")\n","print(first_paragraph.text.strip())\n","# strip() is used to remove leading/trailing white spaces"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FL5KstNpOFjW"},"outputs":[],"source":["#### Task 4: Working with BeautifulSoup and lxml (xml) parser\n","\n","### 1 -  Install Python BeautifulSoup and Requests Library\n","import requests\n","from bs4 import BeautifulSoup\n","\n","# Use this xml code\n","drinks_xml = '''\n","\u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e\n","\u003cdrinks\u003e\n","    \u003cdrink\u003e\n","        \u003cname\u003eCoffee\u003c/name\u003e\n","        \u003cprice\u003e2.50\u003c/price\u003e\n","        \u003cingredients\u003eCoffee beans, water\u003c/ingredients\u003e\n","    \u003c/drink\u003e\n","    \u003cdrink\u003e\n","        \u003cname\u003eTea\u003c/name\u003e\n","        \u003cprice\u003e1.80\u003c/price\u003e\n","        \u003cingredients\u003eTea leaves, water\u003c/ingredients\u003e\n","    \u003c/drink\u003e\n","    \u003cdrink\u003e\n","        \u003cname\u003eOrange Juice\u003c/name\u003e\n","        \u003cprice\u003e3.00\u003c/price\u003e\n","        \u003cingredients\u003eOrange juice concentrate, water\u003c/ingredients\u003e\n","    \u003c/drink\u003e\n","\u003c/drinks\u003e\n","'''\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k3647pNZNoDV"},"outputs":[],"source":["### 4.2 - Scrap content using BeautifulSoup and lxml (xml) parser.\n","soup = BeautifulSoup(drinks_xml, 'lxml')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1753348231035,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"},"user_tz":240},"id":"NollyG7sP--V","outputId":"46ee4f46-981e-44f8-ee21-085b086e14ca"},"outputs":[{"name":"stdout","output_type":"stream","text":["[\u003cdrink\u003e\n","\u003cname\u003eCoffee\u003c/name\u003e\n","\u003cprice\u003e2.50\u003c/price\u003e\n","\u003cingredients\u003eCoffee beans, water\u003c/ingredients\u003e\n","\u003c/drink\u003e, \u003cdrink\u003e\n","\u003cname\u003eTea\u003c/name\u003e\n","\u003cprice\u003e1.80\u003c/price\u003e\n","\u003cingredients\u003eTea leaves, water\u003c/ingredients\u003e\n","\u003c/drink\u003e, \u003cdrink\u003e\n","\u003cname\u003eOrange Juice\u003c/name\u003e\n","\u003cprice\u003e3.00\u003c/price\u003e\n","\u003cingredients\u003eOrange juice concentrate, water\u003c/ingredients\u003e\n","\u003c/drink\u003e]\n"]}],"source":["### 4.3 - Find all drinks information.\n","drinks = soup.find_all('drink')\n","print(drinks)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gd2KZjLVQsvc"},"outputs":[],"source":["##### 4.4 Iterate each drink item into Python objects.\n","for drink in drinks:\n","    name = drink.find('name').text\n","    price = float(drink.find('price').text)\n","    ingredients = drink.find('ingredients').text"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1753348248133,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"},"user_tz":240},"id":"-FRihtqASBB4","outputId":"c40b37be-6e92-41cb-ce23-23b8bb060b8d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Name: Coffee\n","Price: $2.50\n","Ingredients: Coffee beans, water\n","\n","Name: Tea\n","Price: $1.80\n","Ingredients: Tea leaves, water\n","\n","Name: Orange Juice\n","Price: $3.00\n","Ingredients: Orange juice concentrate, water\n","\n"]}],"source":["#### 4.5 - Display all drink items for each drink.\n","    # Print all drinks\n","for drink in drinks:\n","    name = drink.find('name').text\n","    price = float(drink.find('price').text)\n","    ingredients = drink.find('ingredients').text\n","    print(f\"Name: {name}\")\n","    print(f\"Price: ${price:.2f}\")  # 2f converts to 2 float points\n","    print(f\"Ingredients: {ingredients}\")\n","    print()   # Inputs a next line after each drink"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uWZOUz31SeGp"},"outputs":[],"source":["#### Task 5: Working with BeautifulSoup and html.parser\n","\n","#### 1 -   Install Python BeautifulSoup and Requests Library.\n","import requests\n","\n","from bs4 import BeautifulSoup\n","\n","# HTML content of the story\n","story_html = \"\"\"\n","\u003c!DOCTYPE html\u003e\n","\u003chtml lang=\"en\"\u003e\n","\u003chead\u003e\n","    \u003cmeta charset=\"UTF-8\"\u003e\n","    \u003ctitle\u003eThe Magic Garden\u003c/title\u003e\n","\u003c/head\u003e\n","\u003cbody\u003e\n","    \u003ch1 class=\"title\"\u003eThe Magic Garden\u003c/h1\u003e\n","\n","    \u003cp\u003eOnce upon a time, in a faraway land, there existed a magical garden where\u003c/p\u003e\n","\n","    \u003cdiv class=\"characters\"\u003e\n","        \u003cp class=\"character\" id=\"princess\"\u003ePrincess Lily\u003c/p\u003e\n","        \u003cp class=\"character\" id=\"wizard\"\u003eWizard Merlin\u003c/p\u003e\n","        \u003cp class=\"character\" id=\"unicorn\"\u003eUnicorn Sparkle\u003c/p\u003e\n","    \u003c/div\u003e\n","\n","    \u003cp\u003eThese characters roamed freely among the enchanted flowers and shimmering ponds.\u003c/p\u003e\n","\n","    \u003cdiv class=\"story-arc\"\u003e\n","        \u003ch2\u003eChapter 1: The Discovery\u003c/h2\u003e\n","        \u003cp\u003eOne day, Princess Lily stumbled upon a hidden path that led to a secret grove...\u003c/p\u003e\n","    \u003c/div\u003e\n","\n","    \u003cdiv class=\"story-arc\"\u003e\n","        \u003ch2\u003eChapter 2: The Quest\u003c/h2\u003e\n","        \u003cp\u003eWith the help of Wizard Merlin and Unicorn Sparkle, Princess Lily embarked on a quest...\u003c/p\u003e\n","    \u003c/div\u003e\n","\n","    \u003cdiv class=\"story-arc\"\u003e\n","        \u003ch2\u003eChapter 3: The Triumph\u003c/h2\u003e\n","        \u003cp\u003eAfter overcoming many challenges, they finally discovered the source of the garden's magic...\u003c/p\u003e\n","    \u003c/div\u003e\n","\u003c/body\u003e\n","\u003c/html\u003e\n","\"\"\"\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IDQ4WE-gS1Pp"},"outputs":[],"source":["### 5.2 - Scrap content using BeautifulSoup and html.parser.\n","soup = BeautifulSoup(story_html, 'html.parser')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1753348257042,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"},"user_tz":240},"id":"nD_XLTDvTjhD","outputId":"ebed5493-d131-4f29-ef2d-146d4e357691"},"outputs":[{"name":"stdout","output_type":"stream","text":["Head tag:\n","\u003chead\u003e\n","\u003cmeta charset=\"utf-8\"/\u003e\n","\u003ctitle\u003eThe Magic Garden\u003c/title\u003e\n","\u003c/head\u003e\n"]}],"source":["### 5.3 - Display the head tag.\n","head_tag = soup.head\n","print(\"Head tag:\")\n","print(head_tag)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1753348259300,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"},"user_tz":240},"id":"_2O2PobpT-7i","outputId":"36df5784-51a8-43a3-f101-2b9eb6538fcf"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u003ctitle\u003eThe Magic Garden\u003c/title\u003e\n"]}],"source":["### 5.4 - Display the title tag.\n","print(soup.title)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1753348260858,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"},"user_tz":240},"id":"8PeH1YFSUKk9","outputId":"60bebc32-4076-4279-886b-2565506fb4c5"},"outputs":[{"name":"stdout","output_type":"stream","text":["The Magic Garden\n"]}],"source":["### 5.5 - Display the text in the title tag.\n","print(soup.title.string)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1753348263189,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"},"user_tz":240},"id":"C2SZeEZWUWq8","outputId":"cbd91ce2-35bd-4979-fbbd-ce808c68851a"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u003cp\u003eOnce upon a time, in a faraway land, there existed a magical garden where\u003c/p\u003e\n"]}],"source":["### 5.6 - Display the p class in the body tag.\n","print(soup.body.p)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1753348264732,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"},"user_tz":240},"id":"MUmlfdKqU2jT","outputId":"e83172fb-3c4f-44b9-eaa3-418d6ea2166e"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u003cdiv class=\"characters\"\u003e\n","\u003cp class=\"character\" id=\"princess\"\u003ePrincess Lily\u003c/p\u003e\n","\u003cp class=\"character\" id=\"wizard\"\u003eWizard Merlin\u003c/p\u003e\n","\u003cp class=\"character\" id=\"unicorn\"\u003eUnicorn Sparkle\u003c/p\u003e\n","\u003c/div\u003e\n"]}],"source":["### 5.7 -  Display the div class in the body tag.\n","print(soup.body.div)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1753348268719,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"},"user_tz":240},"id":"lUsZXNCRVCGZ","outputId":"f853b35b-88bc-488a-8abc-95e026a6f10d"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u003ch1 class=\"title\"\u003eThe Magic Garden\u003c/h1\u003e\n"]}],"source":["### 5.8 - Display h1 tag\n","print(soup.h1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1753348270460,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"},"user_tz":240},"id":"R0EkLLwNVQmK","outputId":"80539b51-2f33-4712-adc9-d05d5ef99626"},"outputs":[{"name":"stdout","output_type":"stream","text":["Title of the story: The Magic Garden\n"]}],"source":["##### 5.9 - Filter based on a string ‘title’ and print the text of the string.\n","title_tag = soup.find('title')\n","print(\"Title of the story:\", title_tag.text)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1753348272724,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"},"user_tz":240},"id":"5Z1ax_IsVh_c","outputId":"f8177087-54dc-46af-afb1-09b707b8d36b"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Characters in the story:\n","\n","\n","Princess Lily\n","\n","\n","Wizard Merlin\n","\n","\n","Unicorn Sparkle\n","\n","\n"]}],"source":["#### 5.10 - Filter based on a regular expression ‘character’ and print each result.\n","# Filter attribute based on a regular expression\n","characters = soup.find(class_=lambda x: x and 'character' in x)\n","print(\"\\nCharacters in the story:\")  #\\n inserts a new line\n","for character in characters:\n","    print(character.text)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45,"status":"ok","timestamp":1753348276030,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"},"user_tz":240},"id":"CvoePMDCWAPx","outputId":"eb2e2dce-4934-4cca-f978-cfb46608c7a2"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Story Arcs:\n","Chapter 1: The Discovery\n","Chapter 2: The Quest\n","Chapter 3: The Triumph\n"]}],"source":["#### 5.11 - Filter based on a list [“story-arc”] and print each result.\n","# Filter by attribute based on a list\n","story_arcs = soup.find_all(class_=[\"story-arc\"])\n","print(\"\\nStory Arcs:\")\n","for arc in story_arcs:\n","    print(arc.h2.text)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1753348278377,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"},"user_tz":240},"id":"SqLNKwBVWXRh","outputId":"c94b8dea-50ff-4d3e-af52-cbcadcc52c29"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Title of the story using a function: The Magic Garden\n"]}],"source":["#### 5.12 - Filter based on a function and print the result.\n","# Filter by attribute based on a function\n","def is_title_tag(tag):\n","    return tag.name == \"h1\" and \"title\" in tag.get('class', [])\n","\n","title_tag = soup.find(is_title_tag)\n","print(\"\\nTitle of the story using a function:\", title_tag.text)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1753348316852,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"},"user_tz":240},"id":"Tk1FnOJMWiUM","outputId":"d73b7973-2ff2-4bcb-ee4a-6f7249559759"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","First div with an 'id' attribute: Princess Lily\n"]}],"source":["#### 5.13 - Filter based on the value True and print each result.\n","# Filter by attribute with value True\n","div_with_id = soup.find(id=True).text\n","print(\"\\nFirst div with an 'id' attribute:\", div_with_id)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOy6HLHOC84dqBumSnov11B","name":"","provenance":[{"file_id":"17f_xF-njeZnFTaNmZrixL0FAw2yo4Q-K","timestamp":1753348324010}],"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
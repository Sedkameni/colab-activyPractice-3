{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"cfw7cwwFrq47"},"outputs":[],"source":["import requests\n","import pandas as pd\n","from bs4 import BeautifulSoup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sJNYasyKrq47"},"outputs":[],"source":["url = 'https://jsonplaceholder.typicode.com/posts/'\n","# Add a payload dictionary\n","payload = {\"id\": [16, 17, 19], \"userdId\":2}\n","\n","# Get request to API\n","response = requests.get(url, params=payload)\n","\n","# Print the response\n","response_json = response.json()\n","for i in response_json:\n","    print(i, \"\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t05rFBM1rq48"},"outputs":[],"source":["url = 'https://jsonplaceholder.typicode.com/posts/x'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2kYoxYQerq49"},"outputs":[],"source":["# Send a GET request to the URL\n","response = requests.get(url)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8s2LvVhDrq49"},"outputs":[],"source":["# Check if request was successful (status code 200)\n","if response.status_code == 200:\n","    print(\"successful: \", response.text)\n","else:\n","    print(\"Error\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X7KdkQwXrq49"},"outputs":[],"source":["# URL of a webpage with food-related data\n","food_url = 'https://en.wikipedia.org/wiki/List_of_cuisines'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FX7gbX3irq4-"},"outputs":[],"source":["# Read HTML tables from the webpage\n","food_tables = pd.read_html(food_url) # Reads HTML tables (i.e., anything inside <table> tags)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6u-FbkFSrq4-"},"outputs":[],"source":["# Print the number of tables found\n","print(f\"Number of tables found on the food webpage: {len(food_tables)}\")\n","# print(\"Number of tables found on the food webpage:\", len(food_tables))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8N5TWZHGrq4_"},"outputs":[],"source":["# Display the first table\n","print(food_tables[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iOOS6Le-rq4_"},"outputs":[],"source":["# Display the next table\n","print(food_tables[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4aHCC6SErq5A"},"outputs":[],"source":["# URL to scrape data from\n","url = 'https://en.wikipedia.org/wiki/Beautiful_Soup_(HTML_parser)'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ppI4HCc1rq5A"},"outputs":[],"source":["# GET request to the URL\n","response = requests.get(url)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8rjdFDLkrq5A"},"outputs":[],"source":["# Parse the HTML content\n","soup = BeautifulSoup(response.content, 'html5lib')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CEdok3TErq5B"},"outputs":[],"source":["# Find and extract the first paragraph\n","first_paragraph = soup.find('p')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T4kSsRpErq5B"},"outputs":[],"source":["# Print the text of the first paragraph\n","print(\"First paragraph of the article:\")\n","print(first_paragraph.text.strip())\n","# strip() is used to remove leading/trailing white spaces"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WcyBB_yPrq5B"},"outputs":[],"source":["# Use this xml code\n","drinks_xml = '''\n","<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n","<drinks>\n","    <drink>\n","        <name>Coffee</name>\n","        <price>2.50</price>\n","        <ingredients>Coffee beans, water</ingredients>\n","    </drink>\n","    <drink>\n","        <name>Tea</name>\n","        <price>1.80</price>\n","        <ingredients>Tea leaves, water</ingredients>\n","    </drink>\n","    <drink>\n","        <name>Orange Juice</name>\n","        <price>3.00</price>\n","        <ingredients>Orange juice concentrate, water</ingredients>\n","    </drink>\n","</drinks>\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ilFSBl0Brq5B"},"outputs":[],"source":["# Parse XML with BeautifulSoup using 'xml' parser\n","soup = BeautifulSoup(drinks_xml, 'xml')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IboZ3n7Nrq5C"},"outputs":[],"source":["# Extract information from the XML document\n","drinks = soup.find_all('drink')\n","drinks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"12i3gTbhrq5C"},"outputs":[],"source":["for drink in drinks:\n","    name = drink.find('name').text\n","    price = float(drink.find('price').text)\n","    ingredients = drink.find('ingredients').text\n","      # Print all drinks\n","    print(f\"Name: {name}\")\n","    print(f\"Price: ${price:.2f}\")  # 2f converts to 2 float points\n","    print(f\"Ingredients: {ingredients}\")\n","    print()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7dRFLIuIrq5C"},"outputs":[],"source":["# HTML content of the story\n","story_html = \"\"\"\n","<!DOCTYPE html>\n","<html lang=\"en\">\n","<head>\n","    <meta charset=\"UTF-8\">\n","    <title> The Magic Garden</title>\n","</head>\n","<body>\n","    <h1 class=\"title\">The Magic Garden</h1>\n","\n","    <p>Once upon a time, in a faraway land, there existed a magical garden where</p>\n","\n","    <div class=\"characters\">\n","        <p class=\"character\" id=\"princess\">Princess Lily</p>\n","        <p class=\"character\" id=\"wizard\">Wizard Merlin</p>\n","        <p class=\"character\" id=\"unicorn\">Unicorn Sparkle</p>\n","    </div>\n","\n","    <p>These characters roamed freely among the enchanted flowers and shimmering ponds.</p>\n","\n","    <div class=\"story-arc\">\n","        <h2>Chapter 1: The Discovery</h2>\n","        <p>One day, Princess Lily stumbled upon a hidden path that led to a secret grove...</p>\n","    </div>\n","\n","    <div class=\"story-arc\">\n","        <h2>Chapter 2: The Quest</h2>\n","        <p>With the help of Wizard Merlin and Unicorn Sparkle, Princess Lily embarked on a quest...</p>\n","    </div>\n","\n","    <div class=\"story-arc\">\n","        <h2>Chapter 3: The Triumph</h2>\n","        <p>After overcoming many challenges, they finally discovered the source of the garden's magic...</p>\n","    </div>\n","</body>\n","</html>\n","\"\"\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LP62NY33rq5C"},"outputs":[],"source":["# Parse the HTML content\n","soup = BeautifulSoup(story_html, 'html.parser')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1eTSYnnrrq5C"},"outputs":[],"source":["# Display the head\n","soup.head"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AmppijgVrq5C"},"outputs":[],"source":["# Display the tile\n","soup.title"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AcQ3vdfrrq5D"},"outputs":[],"source":["# Display the text in title\n","soup.title.string"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ujTOAw3Prq5D"},"outputs":[],"source":["# Display p class in <body> tag\n","soup.body.p # This is the equivalent of running a \".find('p')\". If all paragraphs are desired, a .find_all('p') can be run."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fkl-VvXDrq5D"},"outputs":[],"source":["# Display div class in <body> tag\n","scoop = soup.body.div.text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qG0qUu8lrq5D"},"outputs":[],"source":["print(scoop)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"65KETZrhrq5D"},"outputs":[],"source":["soup.body.div.p"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WPw9MkVRrq5D"},"outputs":[],"source":["# Display <h1> tag\n","soup.h1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k0j7NQoorq5E"},"outputs":[],"source":["# Filter attribute based on a string\n","title_tag = soup.find('title')\n","print(\"Title of the story:\", title_tag.text)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nVGGVIu5rq5E"},"outputs":[],"source":["# Filter attribute based on a regular expression\n","characters = soup.find(class_=lambda x: x and 'character' in x)\n","print(\"\\nCharacters in the story:\")\n","for character in characters:\n","    print(character.text)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hXF5-Jl5rq5E"},"outputs":[],"source":["# Mini-Crash Course on Python Keywords\n","\n","# if, else, class, def, len, print, import\n","\n","# else = \"Sumaira\"\n","# print(else)\n","\n","# import = 50.5\n","# print(import)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5hTOtj45rq5E"},"outputs":[],"source":["# Filter by attribute based on a list\n","story_arcs = soup.find_all(class_=[\"story-arc\"])\n","print(\"\\nStory Arcs:\")\n","for arc in story_arcs:\n","    print(arc.h2.text)\n","    print(arc.p.text)\n","    print(\"\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xoNtxqx3rq5E"},"outputs":[],"source":["# Filter by attribute based on a function\n","def is_title_tag(tag):\n","    return tag.name == \"h1\" and \"title\" in tag.get('class', [])\n","\n","title_tag = soup.find(is_title_tag)\n","print(\"\\nTitle of the story using a function:\", title_tag.text)"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"0tlBcRg0rq5E","executionInfo":{"status":"error","timestamp":1753348103517,"user_tz":240,"elapsed":193,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"}},"outputId":"389ee0e1-a744-445a-ad53-b6caf0c36e8f","colab":{"base_uri":"https://localhost:8080/","height":176}},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'soup' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1-4239364408.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Filter by attribute with value True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdiv_with_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nFirst div with an 'id' attribute:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiv_with_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'soup' is not defined"]}],"source":["# Filter by attribute with value True\n","div_with_id = soup.find(id=True).text\n","print(\"\\nFirst div with an 'id' attribute:\", div_with_id)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":0}
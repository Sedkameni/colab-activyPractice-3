{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPq8esPAYBIhT9vlpB5dNFB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0N2euKR6_EwL","executionInfo":{"status":"ok","timestamp":1751599499047,"user_tz":240,"elapsed":5,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"}},"outputId":"8568ec1a-4fbd-4d40-8bee-756295e38c45"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['.config',\n"," 'inventory_data.csv',\n"," 'customer_data.csv',\n"," 'api_data1.json',\n"," '[Google Colab] Class Demo 9.ipynb',\n"," 'api_data2.json',\n"," 'sales_data1.csv',\n"," 'sales_data2.csv',\n"," 'sample_data']"]},"metadata":{},"execution_count":3}],"source":["## 1 - Dataset Preparation\n","import os\n","# List all files in the current directory\n","os.listdir()"]},{"cell_type":"code","source":["# 2 - Concatenation (Stacking)\n","import pandas as pd\n","df_sales1 = pd.read_csv('sales_data1.csv')\n","df_sales2 = pd.read_csv('sales_data2.csv')\n","combined_sales = pd.concat([df_sales1,df_sales2])\n","print(\"\\nThe first 5 rows of the combined sales are:\\n\", combined_sales.head().to_string())\n","\n","\n","# 3 - Data Merging/Joining\n","## Load customer_data.csv\n","df_customer = pd.read_csv('customer_data.csv')\n","## Use the pd.merge() function to merge the combined sales data with customer data on CustomerID.\n","customer_combined_sales = pd.merge(df_customer,combined_sales, on='CustomerID', how='inner')\n","\n","##Print the first few rows of the merged dataset to verify the join.\n","print(\"\\nThe first 5 rows of the merged dataset (customers and sales) are:\\n\", customer_combined_sales.head().to_string())\n","\n","# 4- Database Joins using SQLite\n","# Create an SQLite database and load sales and inventory data. Perform SQL joins to integrate these datasets.\n","import sqlite3\n","\n","df_invetory = pd.read_csv('inventory_data.csv')\n","# Create a connection to an SQLite database using sqlite3.\n","conn = sqlite3.connect('retail_data.db')\n","\n","# Load the combined_sales_data and inventory_data.csv into the database as tables.\n","# Load combined sales data into SQLite\n","combined_sales.to_sql('sales', conn, index=False, if_exists='replace')\n","df_invetory.to_sql('inventory', conn, index=False, if_exists='replace')\n","\n","# Perform an SQL join on ProductID to combine the sales and inventory data.\n","query = \"\"\"\n","    SELECT sales.*, inventory.ProductName, inventory.StockLevel\n","    FROM sales\n","    JOIN inventory ON sales.ProductID = inventory.ProductID\n","\"\"\"\n","\n","merged_db_data = pd.read_sql_query(query, conn)\n","# Print the first few rows of the joined dataset to verify the join.\n","print(\"\\nThe first 5 rows of the joined dataset are:\\n\", merged_db_data.head().to_string())\n","\n","\n","\n","# 5 - API Integration\n","\n","import requests\n","##  Use a simulated API provided and combine the results with existing datasets.\n","#  Load the API response data from api_data1.json and api_data2.json (assuming these are simulated responses).\n","api_data1 = pd.read_json('api_data1.json')\n","api_data2 = pd.read_json('api_data2.json')\n","\n","#  Use pd.concat() to concatenate the API data.\n","combined_api_data = pd.concat([api_data1, api_data2])\n","#  Print the first few rows of the combined API dataset to verify.\n","print(\"\\nThe first 5 rows of the combined API dataset are:\\n\", combined_api_data.head().to_string())\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mkSIqNP-_F7f","executionInfo":{"status":"ok","timestamp":1751602023806,"user_tz":240,"elapsed":73,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"}},"outputId":"a801e858-0738-41d7-ea09-199f294cac47"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","The first 5 rows of the combined sales are:\n","    OrderID  CustomerID  ProductID  Quantity   OrderDate\n","0     1001           1        101         5  01/08/2024\n","1     1002           2        103         2  02/08/2024\n","2     1003           1        102         1  03/08/2024\n","0     1004           3        104         4  04/08/2024\n","1     1005           4        105         3  05/08/2024\n","\n","The first 5 rows of the merged dataset (customers and sales) are:\n","    CustomerID   CustomerName ContactName Country  OrderID  ProductID  Quantity   OrderDate\n","0           1       John Doe        John     USA     1001        101         5  01/08/2024\n","1           1       John Doe        John     USA     1003        102         1  03/08/2024\n","2           2     Jane Smith        Jane  Canada     1002        103         2  02/08/2024\n","3           3    Emily Davis       Emily     USA     1004        104         4  04/08/2024\n","4           4  Michael Brown     Michael      UK     1005        105         3  05/08/2024\n","\n","The first 5 rows of the joined dataset are:\n","    OrderID  CustomerID  ProductID  Quantity   OrderDate ProductName  StockLevel\n","0     1001           1        101         5  01/08/2024    Widget A          50\n","1     1002           2        103         2  02/08/2024    Widget C         120\n","2     1003           1        102         1  03/08/2024    Widget B          35\n","3     1004           3        104         4  04/08/2024    Widget D          75\n","4     1005           4        105         3  05/08/2024    Widget E         200\n","\n","The first 5 rows of the combined API dataset are:\n","    ProductID ProductName  Price\n","0        101    Widget A     25\n","1        102    Widget B     35\n","0        103    Widget C     45\n","1        104    Widget D     55\n"]}]}]}
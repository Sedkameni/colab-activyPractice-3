{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPi7WPi0PyO4R+CAt/K5EKX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fZgexnWuV_ib","executionInfo":{"status":"ok","timestamp":1755104490462,"user_tz":240,"elapsed":3791,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"}},"outputId":"0e5dbca9-839a-4f7c-b9b0-2ec128f2ee78"},"outputs":[{"output_type":"stream","name":"stdout","text":["   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n","0         0       3    male  22.0      1      0   7.2500        S  Third   \n","1         1       1  female  38.0      1      0  71.2833        C  First   \n","2         1       3  female  26.0      0      0   7.9250        S  Third   \n","3         1       1  female  35.0      1      0  53.1000        S  First   \n","4         0       3    male  35.0      0      0   8.0500        S  Third   \n","\n","     who  adult_male deck  embark_town alive  alone  \n","0    man        True  NaN  Southampton    no  False  \n","1  woman       False    C    Cherbourg   yes  False  \n","2  woman       False  NaN  Southampton   yes   True  \n","3  woman       False    C  Southampton   yes  False  \n","4    man        True  NaN  Southampton    no   True  \n","         survived      pclass         age       sibsp       parch        fare\n","count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n","mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n","std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n","min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n","25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n","50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n","75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n","max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n"]}],"source":["### Task 1:\n","### Import libraries. Load and explore the \"titanic.csv\" seaborn dataset available at the bottom of this page.\n","### You can also use sns.load_dataset(\"titanic\") to load the dataset.\n","import seaborn as sns\n","import pandas as pd\n","\n","# Load the Titanic dataset\n","titanic = sns.load_dataset(\"titanic\")\n","\n","# Display the first few rows\n","print(titanic.head())\n","\n","# Describe the dataset\n","print(titanic.describe())"]},{"cell_type":"code","source":["#### 1.2 - Groupby and Aggregation Functions: Group by 'sex' and 'class', then calculate the mean and standard deviation of 'age' and 'fare'.\n","# Group by 'sex' and 'class', then calculate the mean and standard deviation of 'age' and 'fare'\n","grouped = titanic.groupby(['sex', 'class'], observed=True).agg({\n","    'age': ['mean', 'std'],\n","    'fare': ['mean', 'std']\n","})\n","print(grouped)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H-yoKzaFYVvs","executionInfo":{"status":"ok","timestamp":1755104685538,"user_tz":240,"elapsed":6,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"}},"outputId":"0caf5019-e90d-410a-8107-ab05745a4b1d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["                     age                   fare           \n","                    mean        std        mean        std\n","sex    class                                              \n","female First   34.611765  13.612052  106.125798  74.259988\n","       Second  28.722973  12.872702   21.970121  10.891796\n","       Third   21.750000  12.729964   16.118810  11.690314\n","male   First   41.281386  15.139570   67.226127  77.548021\n","       Second  30.740707  14.793894   19.741782  14.922235\n","       Third   26.507589  12.159514   12.661633  11.681696\n"]}]},{"cell_type":"code","source":["### 1.3 - Applying Functions: Group by 'sex' and 'class', then apply a custom function to calculate the range of 'age'.\n","# Custom function to calculate the range\n","def calc_range(x):\n","    return x.max() - x.min()\n","\n","# Group by 'sex' and 'class', then apply the custom function to 'age'\n","grouped = titanic.groupby(['sex', 'class'], observed=True)['age'].apply(calc_range)\n","\n","print(grouped)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MHQu8efFZ13l","executionInfo":{"status":"ok","timestamp":1755105247971,"user_tz":240,"elapsed":5,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"}},"outputId":"13434a48-368f-4eff-c766-80e8d4d02b0e"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["sex     class \n","female  First     61.00\n","        Second    55.00\n","        Third     62.25\n","male    First     79.08\n","        Second    69.33\n","        Third     73.58\n","Name: age, dtype: float64\n"]}]},{"cell_type":"code","source":["### 1.4 - Group Transforms: Group by 'sex' and 'class', then calculate the z-score of 'fare' within each group.\n","from scipy.stats import zscore\n","\n","# Calculate the z-score of 'fare' within each group\n","titanic['fare_zscore'] = titanic.groupby(['sex', 'class'], observed=True)['fare'].transform(zscore)\n","\n","print(titanic.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bFxQcQFubRQD","executionInfo":{"status":"ok","timestamp":1755105651801,"user_tz":240,"elapsed":147,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"}},"outputId":"1a14ed86-f33b-4375-e087-f4d197a788b1"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n","0         0       3    male  22.0      1      0   7.2500        S  Third   \n","1         1       1  female  38.0      1      0  71.2833        C  First   \n","2         1       3  female  26.0      0      0   7.9250        S  Third   \n","3         1       1  female  35.0      1      0  53.1000        S  First   \n","4         0       3    male  35.0      0      0   8.0500        S  Third   \n","\n","     who  adult_male deck  embark_town alive  alone  fare_zscore  \n","0    man        True  NaN  Southampton    no  False    -0.463926  \n","1  woman       False    C    Cherbourg   yes  False    -0.471712  \n","2  woman       False  NaN  Southampton   yes   True    -0.703352  \n","3  woman       False    C  Southampton   yes  False    -0.717885  \n","4    man        True  NaN  Southampton    no   True    -0.395344  \n"]}]},{"cell_type":"code","source":["### 1.5 - Iterating Over Groups and Selecting Columns: Iterate over the groups of 'sex' and calculate the mean age for each group.\n","# Iterate over the groups of 'sex' and calculate the mean age for each group\n","for sex, group in titanic.groupby('sex'):\n","    print(f\"Sex: {sex}\")\n","    print(group['age'].mean())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6ojNTRKddNJg","executionInfo":{"status":"ok","timestamp":1755105906973,"user_tz":240,"elapsed":5,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"}},"outputId":"f3029421-7127-438f-df66-a39260507dc3"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Sex: female\n","27.915708812260537\n","Sex: male\n","30.72664459161148\n"]}]},{"cell_type":"code","source":["#### 1.6 - Selecting Columns: Group by 'sex' and 'class', then select the 'fare' column and calculate its mean.\n","# Group by 'sex' and 'class', then select the 'fare' column and calculate its mean\n","grouped = titanic.groupby(['sex', 'class'], observed=True)['fare'].mean()\n","\n","print(grouped)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Zl8w2HCe05k","executionInfo":{"status":"ok","timestamp":1755106342386,"user_tz":240,"elapsed":9,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"}},"outputId":"532bca93-e35a-4aae-cb41-454f90a95d27"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["sex     class \n","female  First     106.125798\n","        Second     21.970121\n","        Third      16.118810\n","male    First      67.226127\n","        Second     19.741782\n","        Third      12.661633\n","Name: fare, dtype: float64\n"]}]},{"cell_type":"code","source":["### 1.7 - Advanced Grouping and Aggregation: Grouping with Dictionary or Series. Group by a dictionary mapping 'class' to 'Deck' levels and calculate the mean fare.\n","# Dictionary mapping 'class' to 'Deck' levels\n","deck_mapping = {\n","    'First': 'A',\n","    'Second': 'B',\n","    'Third': 'C'\n","}\n","\n","# Group by the dictionary mapping and calculate the mean fare\n","map_grouping = titanic.groupby(titanic['class'].map(deck_mapping), observed=True)['fare'].mean()\n","\n","print(map_grouping)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"06PCMqGffhbq","executionInfo":{"status":"ok","timestamp":1755107105808,"user_tz":240,"elapsed":58,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"}},"outputId":"56dc91e4-9f6b-4a5b-ea12-6614864ff43d"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["class\n","A    84.154687\n","B    20.662183\n","C    13.675550\n","Name: fare, dtype: float64\n"]}]},{"cell_type":"code","source":["### 1.8 - Grouping with Functions: Group by whether the passenger is a minor (age < 18) and calculate the mean fare.\n","# Function to determine if a passenger is a minor\n","def is_minor(age):\n","    return age < 18\n","\n","# Group by the function and calculate the mean fare\n","age_grouped = titanic.groupby(titanic['age'].apply(is_minor))['fare'].mean()\n","\n","print(age_grouped)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TgFXE7naiZQf","executionInfo":{"status":"ok","timestamp":1755107401072,"user_tz":240,"elapsed":13,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"}},"outputId":"ec5bbf65-a6b9-40c9-d0e8-6a7dff8a7e71"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["age\n","False    32.347043\n","True     31.220798\n","Name: fare, dtype: float64\n"]}]},{"cell_type":"code","source":["### 1.9 - Grouping with Index Levels and Column-Wise: Group by 'sex' and 'class' index levels and calculate the mean age and fare.\n","# Set multi-level index\n","titanic.set_index(['sex', 'class'], inplace=True)\n","\n","# Group by index levels and calculate the mean age and fare\n","grouped = titanic.groupby(level=['sex', 'class'], observed=True).agg({'age': 'mean', 'fare': 'mean'})\n","\n","print(grouped)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ftxp31A_jw4d","executionInfo":{"status":"ok","timestamp":1755107831293,"user_tz":240,"elapsed":12,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"}},"outputId":"cb5720aa-6fcd-43e0-edc1-bd80a374c205"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["                     age        fare\n","sex    class                        \n","female First   34.611765  106.125798\n","       Second  28.722973   21.970121\n","       Third   21.750000   16.118810\n","male   First   41.281386   67.226127\n","       Second  30.740707   19.741782\n","       Third   26.507589   12.661633\n"]}]},{"cell_type":"code","source":["### 1.10 - Grouping with Multiple Functions: Group by 'sex' and 'class', then calculate the mean, median, and count of 'age'.\n","# Group by 'sex' and 'class', then calculate the mean, median, and count of 'age'\n","sc_grouped = titanic.groupby(['sex', 'class'], observed=True)['age'].agg(['mean', 'median', 'count'])\n","\n","print(sc_grouped)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uLJd2P_4lvjr","executionInfo":{"status":"ok","timestamp":1755108726679,"user_tz":240,"elapsed":7,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"}},"outputId":"d5c68779-3008-4089-c743-ea4e12aaa24d"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["                    mean  median  count\n","sex    class                           \n","female First   34.611765    35.0     85\n","       Second  28.722973    28.0     74\n","       Third   21.750000    21.5    102\n","male   First   41.281386    40.0    101\n","       Second  30.740707    30.0     99\n","       Third   26.507589    25.0    253\n"]}]},{"cell_type":"code","source":["### 1.11 - Pivot tables and Crosstabulation: Create a pivot table to calculate the mean fare for each combination of 'sex' and 'class'.\n","# Create a pivot table to calculate the mean fare for each combination of 'sex' and 'class'\n","pivot_table = titanic.pivot_table(values='fare', index='sex', columns='class', aggfunc='mean')\n","\n","print(pivot_table)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"afvgGd_onhI6","executionInfo":{"status":"ok","timestamp":1755108724731,"user_tz":240,"elapsed":6,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"}},"outputId":"2f57b99d-b717-4e05-c82b-0407a954fea3"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["class        First     Second      Third\n","sex                                     \n","female  106.125798  21.970121  16.118810\n","male     67.226127  19.741782  12.661633\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-4120337148.py:3: FutureWarning: The default value of observed=False is deprecated and will change to observed=True in a future version of pandas. Specify observed=False to silence this warning and retain the current behavior\n","  pivot_table = titanic.pivot_table(values='fare', index='sex', columns='class', aggfunc='mean')\n"]}]},{"cell_type":"code","source":["### 1.12 - Crosstab: Create a crosstab to count the number of passengers for each combination of 'sex' and 'class'.\n","# Create a crosstab to count the number of passengers for each combination of 'who' and 'sex'\n","crosstab = pd.crosstab(titanic['who'], titanic['fare'].mean())\n","\n","print(crosstab)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ppLAE0eyoiek","executionInfo":{"status":"ok","timestamp":1755108788096,"user_tz":240,"elapsed":9,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"}},"outputId":"cca5256f-3792-4148-9761-65f5473c73ee"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["col_0  32.204208\n","who             \n","child         83\n","man          537\n","woman        271\n"]}]},{"cell_type":"code","source":["### Task 2:\n","### 2.1 - Import libraries. Create a Students Performance Dataset.\n","import pandas as pd\n","\n","# Create the students performance dataset\n","data_performance = {\n","    'student_id': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n","    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva', 'Frank', 'Grace', 'Henry', 'Ivy', 'John'],\n","    'math_score': [85, 92, 78, 88, 91, 76, 89, 94, 87, 95],\n","    'english_score': [88, 79, 85, 90, 78, 83, 86, 92, 89, 91]\n","}\n","\n","df_performance = pd.DataFrame(data_performance)\n","print(\"Students Performance Dataset:\")\n","print(df_performance)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xju1G1Ppo1t4","executionInfo":{"status":"ok","timestamp":1755109375960,"user_tz":240,"elapsed":80,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"}},"outputId":"dd64a1c5-0b48-49e8-9c37-5374e72cc19e"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Students Performance Dataset:\n","   student_id     name  math_score  english_score\n","0           1    Alice          85             88\n","1           2      Bob          92             79\n","2           3  Charlie          78             85\n","3           4    David          88             90\n","4           5      Eva          91             78\n","5           6    Frank          76             83\n","6           7    Grace          89             86\n","7           8    Henry          94             92\n","8           9      Ivy          87             89\n","9          10     John          95             91\n"]}]},{"cell_type":"code","source":["### 2.2 - Create a Students Attendance Dataset.\n","# Create the students attendance dataset\n","data_attendance = {\n","    'student_id': [1, 2, 3, 4, 5, 6, 11, 12, 13, 14],\n","    'attendance_days': [180, 175, 190, 185, 178, 172, 160, 165, 170, 175]\n","}\n","\n","df_attendance = pd.DataFrame(data_attendance)\n","print(\"\\nStudents Attendance Dataset:\")\n","print(df_attendance)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"69eFgHVgq_aW","executionInfo":{"status":"ok","timestamp":1755109462263,"user_tz":240,"elapsed":14,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"}},"outputId":"f590f9f7-f343-4a1b-dc40-00449c59c179"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Students Attendance Dataset:\n","   student_id  attendance_days\n","0           1              180\n","1           2              175\n","2           3              190\n","3           4              185\n","4           5              178\n","5           6              172\n","6          11              160\n","7          12              165\n","8          13              170\n","9          14              175\n"]}]},{"cell_type":"code","source":["### 2.3 - Merging Datasets: Merge the Performance and Attendance Datasets on student_id.\n","# Merge the performance and attendance datasets on 'student_id'\n","df_merged = pd.merge(df_performance, df_attendance, on='student_id', how='inner')\n","print(\"\\nMerged Dataset (Inner Join):\")\n","print(df_merged)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KqPL3b5brSlr","executionInfo":{"status":"ok","timestamp":1755109545327,"user_tz":240,"elapsed":15,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"}},"outputId":"90836507-4cd5-4670-e6f3-b7aef807279f"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Merged Dataset (Inner Join):\n","   student_id     name  math_score  english_score  attendance_days\n","0           1    Alice          85             88              180\n","1           2      Bob          92             79              175\n","2           3  Charlie          78             85              190\n","3           4    David          88             90              185\n","4           5      Eva          91             78              178\n","5           6    Frank          76             83              172\n"]}]},{"cell_type":"code","source":["### 2.4 - Perform a Left Merge.\n","# Perform a left merge to keep all students in the performance dataset\n","df_left_merge = pd.merge(df_performance, df_attendance, on='student_id', how='left')\n","print(\"\\nLeft Merge (Keep all students in performance dataset):\")\n","print(df_left_merge)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZlaGxtgkrpOw","executionInfo":{"status":"ok","timestamp":1755109668662,"user_tz":240,"elapsed":5,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"}},"outputId":"a5b2eb11-225a-4b39-89f3-c142899afb07"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Left Merge (Keep all students in performance dataset):\n","   student_id     name  math_score  english_score  attendance_days\n","0           1    Alice          85             88            180.0\n","1           2      Bob          92             79            175.0\n","2           3  Charlie          78             85            190.0\n","3           4    David          88             90            185.0\n","4           5      Eva          91             78            178.0\n","5           6    Frank          76             83            172.0\n","6           7    Grace          89             86              NaN\n","7           8    Henry          94             92              NaN\n","8           9      Ivy          87             89              NaN\n","9          10     John          95             91              NaN\n"]}]},{"cell_type":"code","source":["### 2.5 - Concatenating Datasets: Concatenate the Performance Dataset with Itself\n","# Concatenate the performance dataset with itself\n","df_concat = pd.concat([df_performance, df_performance], ignore_index=True)\n","print(\"\\nConcatenated Dataset (Performance with itself):\")\n","print(df_concat)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aPq5Tw0XsHG7","executionInfo":{"status":"ok","timestamp":1755109796297,"user_tz":240,"elapsed":15,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"}},"outputId":"0971c1a6-b1f2-43d0-acc7-95f8149476d8"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Concatenated Dataset (Performance with itself):\n","    student_id     name  math_score  english_score\n","0            1    Alice          85             88\n","1            2      Bob          92             79\n","2            3  Charlie          78             85\n","3            4    David          88             90\n","4            5      Eva          91             78\n","5            6    Frank          76             83\n","6            7    Grace          89             86\n","7            8    Henry          94             92\n","8            9      Ivy          87             89\n","9           10     John          95             91\n","10           1    Alice          85             88\n","11           2      Bob          92             79\n","12           3  Charlie          78             85\n","13           4    David          88             90\n","14           5      Eva          91             78\n","15           6    Frank          76             83\n","16           7    Grace          89             86\n","17           8    Henry          94             92\n","18           9      Ivy          87             89\n","19          10     John          95             91\n"]}]},{"cell_type":"code","source":["### 2.6 - Concatenate the Performance and Attendance Datasets Along Columns.\n","# Concatenate the performance and attendance datasets along columns\n","df_concat_columns = pd.concat([df_performance, df_attendance], axis=1)\n","print(\"\\nConcatenated Dataset Along Columns:\")\n","print(df_concat_columns)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LFHodSx2sof4","executionInfo":{"status":"ok","timestamp":1755109966330,"user_tz":240,"elapsed":11,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"}},"outputId":"b032dbdc-86cb-40fc-e1ce-d1240ac9978a"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Concatenated Dataset Along Columns:\n","   student_id     name  math_score  english_score  student_id  attendance_days\n","0           1    Alice          85             88           1              180\n","1           2      Bob          92             79           2              175\n","2           3  Charlie          78             85           3              190\n","3           4    David          88             90           4              185\n","4           5      Eva          91             78           5              178\n","5           6    Frank          76             83           6              172\n","6           7    Grace          89             86          11              160\n","7           8    Henry          94             92          12              165\n","8           9      Ivy          87             89          13              170\n","9          10     John          95             91          14              175\n"]}]},{"cell_type":"code","source":["### 2.7 - Combining Datasets with combine_first: Combine Datasets to Fill Missing Values.\n","# Creating another attendance dataset with some overlapping and missing 'attendance_days'\n","data_attendance_new = {\n","    'student_id': [1, 2, 3, 7, 8, 9, 10, 15, 16, 17],\n","    'attendance_days': [182, 176, 191, 175, 178, 173, 165, 169, 174, 168]\n","}\n","\n","df_attendance_new = pd.DataFrame(data_attendance_new)\n","print(\"\\nNew Students Attendance Dataset:\")\n","print(df_attendance_new)\n","\n","# Combine the attendance datasets to fill missing values\n","df_combined = df_attendance.combine_first(df_attendance_new)\n","print(\"\\nCombined Attendance Dataset (Using combine_first):\")\n","print(df_combined)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4f1VC8vZtTTs","executionInfo":{"status":"ok","timestamp":1755110324032,"user_tz":240,"elapsed":11,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"}},"outputId":"b789137e-1ef6-414a-f53d-5ab8f87cddb9"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","New Students Attendance Dataset:\n","   student_id  attendance_days\n","0           1              182\n","1           2              176\n","2           3              191\n","3           7              175\n","4           8              178\n","5           9              173\n","6          10              165\n","7          15              169\n","8          16              174\n","9          17              168\n","\n","Combined Attendance Dataset (Using combine_first):\n","   student_id  attendance_days\n","0           1              180\n","1           2              175\n","2           3              190\n","3           4              185\n","4           5              178\n","5           6              172\n","6          11              160\n","7          12              165\n","8          13              170\n","9          14              175\n"]}]},{"cell_type":"code","source":["### - Task 3:\n","### 3.1 - Import libraries\n","import numpy as np\n","import pandas as pd\n","\n","### 3.2 - Use NumPy to create a large random dataset with 1,000,000 rows and 10 columns, and load it into a Pandas DataFrame.\n","# Set the random seed for reproducibility\n","np.random.seed(42)\n","\n","# Create a large random dataset with 1,000,000 rows and 10 columns\n","data = np.random.rand(1000000, 10)\n","\n","# Create column names\n","columns = [f'col_{i}' for i in range(10)]\n","\n","# Load the dataset into a Pandas DataFrame\n","df_large = pd.DataFrame(data, columns=columns)\n","\n","print(\"Large Random Dataset:\")\n","print(df_large.head())\n","print(f\"\\nDataset shape: {df_large.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t7jwYQcjur14","executionInfo":{"status":"ok","timestamp":1755110589148,"user_tz":240,"elapsed":222,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"}},"outputId":"b13ca8c2-5804-4e99-f009-3c17cd23f16e"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Large Random Dataset:\n","      col_0     col_1     col_2     col_3     col_4     col_5     col_6  \\\n","0  0.374540  0.950714  0.731994  0.598658  0.156019  0.155995  0.058084   \n","1  0.020584  0.969910  0.832443  0.212339  0.181825  0.183405  0.304242   \n","2  0.611853  0.139494  0.292145  0.366362  0.456070  0.785176  0.199674   \n","3  0.607545  0.170524  0.065052  0.948886  0.965632  0.808397  0.304614   \n","4  0.122038  0.495177  0.034389  0.909320  0.258780  0.662522  0.311711   \n","\n","      col_7     col_8     col_9  \n","0  0.866176  0.601115  0.708073  \n","1  0.524756  0.431945  0.291229  \n","2  0.514234  0.592415  0.046450  \n","3  0.097672  0.684233  0.440152  \n","4  0.520068  0.546710  0.184854  \n","\n","Dataset shape: (1000000, 10)\n"]}]},{"cell_type":"code","source":["### 3.3 - Using to_pickle and read_pickle: Save the DataFrame using the to_pickle function.\n","# Save the DataFrame to a pickle file\n","pickle_filename = 'large_dataset.pkl'\n","df_large.to_pickle(pickle_filename)\n","\n","print(f\"\\nDataFrame saved to pickle file: {pickle_filename}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9dTANaTbvv5u","executionInfo":{"status":"ok","timestamp":1755110704446,"user_tz":240,"elapsed":54,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"}},"outputId":"534aaa41-f100-4355-be3a-854564d73fa3"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","DataFrame saved to pickle file: large_dataset.pkl\n"]}]},{"cell_type":"code","source":["### 3.4 - Read the DataFrame back from the pickle file using the read_pickle function.\n","# Read the DataFrame from the pickle file\n","df_loaded = pd.read_pickle(pickle_filename)\n","\n","print(\"\\nLoaded DataFrame from Pickle File:\")\n","print(df_loaded.head())\n","print(f\"\\nLoaded DataFrame shape: {df_loaded.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gYpDFXQFwDvW","executionInfo":{"status":"ok","timestamp":1755110764016,"user_tz":240,"elapsed":65,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"}},"outputId":"b050c900-fd4b-4ef1-c5dd-3c549bab228e"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Loaded DataFrame from Pickle File:\n","      col_0     col_1     col_2     col_3     col_4     col_5     col_6  \\\n","0  0.374540  0.950714  0.731994  0.598658  0.156019  0.155995  0.058084   \n","1  0.020584  0.969910  0.832443  0.212339  0.181825  0.183405  0.304242   \n","2  0.611853  0.139494  0.292145  0.366362  0.456070  0.785176  0.199674   \n","3  0.607545  0.170524  0.065052  0.948886  0.965632  0.808397  0.304614   \n","4  0.122038  0.495177  0.034389  0.909320  0.258780  0.662522  0.311711   \n","\n","      col_7     col_8     col_9  \n","0  0.866176  0.601115  0.708073  \n","1  0.524756  0.431945  0.291229  \n","2  0.514234  0.592415  0.046450  \n","3  0.097672  0.684233  0.440152  \n","4  0.520068  0.546710  0.184854  \n","\n","Loaded DataFrame shape: (1000000, 10)\n"]}]},{"cell_type":"code","source":["### 3.5 - Verifying Data Integrity: Verify that the loaded DataFrame is identical to the original DataFrame.\n","# Verify that the loaded DataFrame is identical to the original DataFrame\n","is_identical = df_large.equals(df_loaded)\n","print(f\"\\nIs the loaded DataFrame identical to the original? {is_identical}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gsDMZAohwUUf","executionInfo":{"status":"ok","timestamp":1755110942264,"user_tz":240,"elapsed":113,"user":{"displayName":"Sedrick Kameni","userId":"07295528143734832644"}},"outputId":"4963022f-b678-4a5d-8705-9130e70ed8f3"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Is the loaded DataFrame identical to the original? True\n"]}]}]}
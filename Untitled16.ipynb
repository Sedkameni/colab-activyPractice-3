{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMezAxw4SGJ2w7/uLjC26Ji"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"OBAUBnqItxo3"},"outputs":[],"source":["# ============================================================================\n","# CELL 8: Create Results DataFrame\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"COMPLETE RESULTS TABLE\")\n","print(\"=\" * 70)\n","\n","results_df = pd.DataFrame({\n","    'X': X_values,\n","    'Actual Y': Y_values,\n","    'Predicted Y': Y_pred_manual,\n","    'Residual (ε)': residuals,\n","    'Equation': [f\"{beta[0]} + {beta[1]}×{x} = {beta[0] + beta[1]*x}\" for x in X_values]\n","})\n","\n","print(\"\\n\", results_df.to_string(index=False))\n","\n","\n","# ============================================================================\n","# CELL 9: scikit-learn Implementation with Train/Test Split\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"SCIKIT-LEARN IMPLEMENTATION WITH TRAIN/TEST SPLIT\")\n","print(\"=\" * 70)\n","\n","# Prepare data for sklearn (needs 2D array for X)\n","X_sklearn = X_values.reshape(-1, 1)\n","Y_sklearn = Y_values\n","\n","print(f\"\\nOriginal Dataset Size: {len(X_sklearn)} samples\")\n","\n","# Split data into train (60%) and test (40%)\n","X_train, X_test, Y_train, Y_test = train_test_split(\n","    X_sklearn, Y_sklearn, test_size=0.4, random_state=42\n",")\n","\n","print(f\"Training Set Size: {len(X_train)} samples\")\n","print(f\"Test Set Size: {len(X_test)} samples\")\n","print(f\"\\nTraining Data:\")\n","print(f\"X_train = {X_train.flatten()}\")\n","print(f\"Y_train = {Y_train}\")\n","print(f\"\\nTest Data:\")\n","print(f\"X_test = {X_test.flatten()}\")\n","print(f\"Y_test = {Y_test}\")\n","\n","# Create and fit the model on training data\n","model = LinearRegression()\n","model.fit(X_train, Y_train)\n","\n","# Print coefficients\n","print(\"\\n\" + \"-\" * 70)\n","print(\"MODEL COEFFICIENTS (from sklearn)\")\n","print(\"-\" * 70)\n","print(f\"Intercept (β₀): {model.intercept_:.4f}\")\n","print(f\"Slope (β₁): {model.coef_[0]:.4f}\")\n","print(f\"\\n sklearn Equation: y = {model.intercept_:.4f} + {model.coef_[0]:.4f}x\")\n","\n","# Compare with manual calculation\n","print(\"\\n\" + \"-\" * 70)\n","print(\"COMPARISON: Manual vs sklearn\")\n","print(\"-\" * 70)\n","print(f\"Manual Intercept: {beta[0]:.4f}\")\n","print(f\"sklearn Intercept: {model.intercept_:.4f}\")\n","print(f\"Difference: {abs(beta[0] - model.intercept_):.10f}\")\n","print()\n","print(f\"Manual Slope: {beta[1]:.4f}\")\n","print(f\"sklearn Slope: {model.coef_[0]:.4f}\")\n","print(f\"Difference: {abs(beta[1] - model.coef_[0]):.10f}\")\n","\n","\n","# ============================================================================\n","# CELL 10: Predictions and Evaluation\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"MODEL EVALUATION\")\n","print(\"=\" * 70)\n","\n","# Predictions on both train and test sets\n","Y_train_pred = model.predict(X_train)\n","Y_test_pred = model.predict(X_test)\n","\n","# Evaluate on training set\n","r2_train = r2_score(Y_train, Y_train_pred)\n","mse_train = mean_squared_error(Y_train, Y_train_pred)\n","mae_train = mean_absolute_error(Y_train, Y_train_pred)\n","rmse_train = np.sqrt(mse_train)\n","\n","# Evaluate on test set\n","r2_test = r2_score(Y_test, Y_test_pred)\n","mse_test = mean_squared_error(Y_test, Y_test_pred)\n","mae_test = mean_absolute_error(Y_test, Y_test_pred)\n","rmse_test = np.sqrt(mse_test)\n","\n","print(\"\\n TRAINING SET METRICS:\")\n","print(f\"R² Score: {r2_train:.4f}\")\n","print(f\"Mean Squared Error (MSE): {mse_train:.4f}\")\n","print(f\"Root Mean Squared Error (RMSE): {rmse_train:.4f}\")\n","print(f\"Mean Absolute Error (MAE): {mae_train:.4f}\")\n","\n","print(\"\\n TEST SET METRICS:\")\n","print(f\"R² Score: {r2_test:.4f}\")\n","print(f\"Mean Squared Error (MSE): {mse_test:.4f}\")\n","print(f\"Root Mean Squared Error (RMSE): {rmse_test:.4f}\")\n","print(f\"Mean Absolute Error (MAE): {mae_test:.4f}\")\n","\n","# Create evaluation comparison DataFrame\n","eval_df = pd.DataFrame({\n","    'Metric': ['R²', 'MSE', 'RMSE', 'MAE'],\n","    'Training Set': [r2_train, mse_train, rmse_train, mae_train],\n","    'Test Set': [r2_test, mse_test, rmse_test, mae_test]\n","})\n","\n","print(\"\\n\" + \"-\" * 70)\n","print(\"METRICS COMPARISON TABLE\")\n","print(\"-\" * 70)\n","print(eval_df.to_string(index=False))\n","\n","\n","# ============================================================================\n","# CELL 11: Visualization 1 - Training and Test Data with Regression Line\n","# ============================================================================\n","\n","plt.figure(figsize=(12, 8))\n","\n","# Plot training data\n","plt.scatter(X_train, Y_train, color='red', s=150, alpha=0.7,\n","           edgecolors='black', linewidth=2, label='Training Data', zorder=5)\n","\n","# Plot test data\n","plt.scatter(X_test, Y_test, color='green', s=150, alpha=0.7,\n","           edgecolors='black', linewidth=2, label='Test Data', zorder=5)\n","\n","# Plot regression line\n","X_line = np.linspace(0.5, 4.5, 100).reshape(-1, 1)\n","Y_line = model.predict(X_line)\n","plt.plot(X_line, Y_line, color='blue', linewidth=3, label='Regression Line', zorder=3)\n","\n","# Add predictions on test set\n","plt.scatter(X_test, Y_test_pred, color='orange', s=100, marker='x',\n","           linewidth=3, label='Test Predictions', zorder=4)\n","\n","# Connect actual and predicted with dashed lines (residuals)\n","for i in range(len(X_test)):\n","    plt.plot([X_test[i], X_test[i]], [Y_test[i], Y_test_pred[i]],\n","            'k--', alpha=0.3, linewidth=1)\n","\n","plt.title('Linear Regression with Train/Test Split\\n' +\n","         f'Equation: y = {model.intercept_:.2f} + {model.coef_[0]:.2f}x',\n","         fontsize=16, fontweight='bold')\n","plt.xlabel('X (Independent Variable)', fontsize=14, fontweight='bold')\n","plt.ylabel('Y (Dependent Variable)', fontsize=14, fontweight='bold')\n","plt.legend(fontsize=12, loc='upper left')\n","plt.grid(True, alpha=0.3)\n","\n","# Add text box with metrics\n","textstr = f'Test Set Metrics:\\nR² = {r2_test:.4f}\\nMSE = {mse_test:.4f}\\nRMSE = {rmse_test:.4f}'\n","props = dict(boxstyle='round', facecolor='wheat', alpha=0.8)\n","plt.text(0.98, 0.02, textstr, transform=plt.gca().transAxes, fontsize=11,\n","        verticalalignment='bottom', horizontalalignment='right', bbox=props)\n","\n","plt.tight_layout()\n","plt.show()\n","\n","print(\"\\nVisualization 1 complete!\")\n","\n","\n","# ============================================================================\n","# CELL 12: Visualization 2 - Residual Plot\n","# ============================================================================\n","\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n","\n","# Residual plot for training data\n","train_residuals = Y_train - Y_train_pred\n","ax1.scatter(Y_train_pred, train_residuals, color='red', s=100,\n","           alpha=0.7, edgecolors='black', linewidth=2)\n","ax1.axhline(y=0, color='blue', linestyle='--', linewidth=2)\n","ax1.set_title('Residual Plot - Training Set', fontsize=14, fontweight='bold')\n","ax1.set_xlabel('Predicted Values', fontsize=12, fontweight='bold')\n","ax1.set_ylabel('Residuals', fontsize=12, fontweight='bold')\n","ax1.grid(True, alpha=0.3)\n","\n","# Residual plot for test data\n","test_residuals = Y_test - Y_test_pred\n","ax2.scatter(Y_test_pred, test_residuals, color='green', s=100,\n","           alpha=0.7, edgecolors='black', linewidth=2)\n","ax2.axhline(y=0, color='blue', linestyle='--', linewidth=2)\n","ax2.set_title('Residual Plot - Test Set', fontsize=14, fontweight='bold')\n","ax2.set_xlabel('Predicted Values', fontsize=12, fontweight='bold')\n","ax2.set_ylabel('Residuals', fontsize=12, fontweight='bold')\n","ax2.grid(True, alpha=0.3)\n","\n","plt.tight_layout()\n","plt.show()\n","\n","print(\"\\nVisualization 2 complete!\")\n","\n","\n","# ============================================================================\n","# CELL 13: Visualization 3 - Actual vs Predicted\n","# ============================================================================\n","\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n","\n","# Training set: Actual vs Predicted\n","ax1.scatter(Y_train, Y_train_pred, color='red', s=150,\n","           alpha=0.7, edgecolors='black', linewidth=2)\n","ax1.plot([Y_train.min(), Y_train.max()], [Y_train.min(), Y_train.max()],\n","        'b--', linewidth=2, label='Perfect Prediction')\n","ax1.set_title('Actual vs Predicted - Training Set', fontsize=14, fontweight='bold')\n","ax1.set_xlabel('Actual Y', fontsize=12, fontweight='bold')\n","ax1.set_ylabel('Predicted Y', fontsize=12, fontweight='bold')\n","ax1.legend(fontsize=11)\n","ax1.grid(True, alpha=0.3)\n","\n","# Add R² annotation\n","textstr = f'R² = {r2_train:.4f}'\n","ax1.text(0.05, 0.95, textstr, transform=ax1.transAxes, fontsize=12,\n","        verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n","\n","# Test set: Actual vs Predicted\n","ax2.scatter(Y_test, Y_test_pred, color='green', s=150,\n","           alpha=0.7, edgecolors='black', linewidth=2)\n","ax2.plot([Y_test.min(), Y_test.max()], [Y_test.min(), Y_test.max()],\n","        'b--', linewidth=2, label='Perfect Prediction')\n","ax2.set_title('Actual vs Predicted - Test Set', fontsize=14, fontweight='bold')\n","ax2.set_xlabel('Actual Y', fontsize=12, fontweight='bold')\n","ax2.set_ylabel('Predicted Y', fontsize=12, fontweight='bold')\n","ax2.legend(fontsize=11)\n","ax2.grid(True, alpha=0.3)\n","\n","# Add R² annotation\n","textstr = f'R² = {r2_test:.4f}'\n","ax2.text(0.05, 0.95, textstr, transform=ax2.transAxes, fontsize=12,\n","        verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n","\n","plt.tight_layout()\n","plt.show()\n","\n","print(\"\\n Visualization 3 complete!\")\n","\n","\n","# ============================================================================\n","# CELL 14: Visualization 4 - Complete Dataset with Manual Calculation\n","# ============================================================================\n","\n","plt.figure(figsize=(12, 8))\n","\n","# Plot all original data points\n","plt.scatter(X_values, Y_values, color='purple', s=200, alpha=0.6,\n","           edgecolors='black', linewidth=2, label='Original Data', zorder=5)\n","\n","# Plot predictions from manual calculation\n","plt.scatter(X_values, Y_pred_manual, color='orange', s=150, marker='D',\n","           alpha=0.8, edgecolors='black', linewidth=2,\n","           label='Manual Predictions', zorder=4)\n","\n","# Plot regression line\n","X_line_extended = np.linspace(0, 5, 100)\n","Y_line_extended = beta[0] + beta[1] * X_line_extended\n","plt.plot(X_line_extended, Y_line_extended, color='red', linewidth=3,\n","        label='Regression Line (Manual)', linestyle='--', zorder=3)\n","\n","# Add residual lines\n","for i in range(len(X_values)):\n","    plt.plot([X_values[i], X_values[i]], [Y_values[i], Y_pred_manual[i]],\n","            'gray', linestyle=':', linewidth=2, alpha=0.5)\n","\n","plt.title('Linear Regression - Manual Matrix Calculation\\n' +\n","         f'y = {beta[0]:.2f} + {beta[1]:.2f}x  |  R² = {R2:.4f}',\n","         fontsize=16, fontweight='bold')\n","plt.xlabel('X (Independent Variable)', fontsize=14, fontweight='bold')\n","plt.ylabel('Y (Dependent Variable)', fontsize=14, fontweight='bold')\n","plt.legend(fontsize=12, loc='upper left')\n","plt.grid(True, alpha=0.3)\n","\n","# Annotate each point\n","for i, (x, y) in enumerate(zip(X_values, Y_values)):\n","    plt.annotate(f'({x}, {y})',\n","                xy=(x, y), xytext=(10, 10),\n","                textcoords='offset points', fontsize=10,\n","                bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7))\n","\n","plt.tight_layout()\n","plt.show()\n","\n","print(\"\\n Visualization 4 complete!\")\n","\n","\n","# ============================================================================\n","# CELL 15: Summary Report\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"FINAL SUMMARY REPORT\")\n","print(\"=\" * 70)\n","\n","print(\"\\n DATASET INFORMATION:\")\n","print(f\"   Total Samples: {len(X_values)}\")\n","print(f\"   Training Samples: {len(X_train)} (60%)\")\n","print(f\"   Test Samples: {len(X_test)} (40%)\")\n","\n","print(\"\\n MODEL COEFFICIENTS:\")\n","print(f\"   Manual Calculation:\")\n","print(f\"      β₀ (Intercept) = {beta[0]:.4f}\")\n","print(f\"      β₁ (Slope) = {beta[1]:.4f}\")\n","print(f\"   sklearn Calculation:\")\n","print(f\"      β₀ (Intercept) = {model.intercept_:.4f}\")\n","print(f\"      β₁ (Slope) = {model.coef_[0]:.4f}\")\n","\n","print(\"\\n REGRESSION EQUATION:\")\n","print(f\"   y = {beta[0]:.2f} + {beta[1]:.2f}x\")\n","\n","print(\"\\n MODEL PERFORMANCE:\")\n","print(f\"   Full Dataset R²: {R2:.4f}\")\n","print(f\"   Training Set R²: {r2_train:.4f}\")\n","print(f\"   Test Set R²: {r2_test:.4f}\")\n","\n","print(\"\\n KEY INSIGHTS:\")\n","if R2 == 1.0:\n","    print(\"  Perfect linear fit on full dataset\")\n","    print(\"  All predictions match actual values exactly\")\n","    print(\" Zero residual error\")\n","else:\n","    print(f\"  Model explains {R2*100:.2f}% of variance\")\n","    print(f\"  Average prediction error: {MAE:.4f}\")\n","\n","if r2_test >= 0.9:\n","    print(\" Excellent performance on test set\")\n","elif r2_test >= 0.7:\n","    print(\" Good performance on test set\")\n","else:\n","    print(\"   Model may need improvement\")\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"ANALYSIS COMPLETE!\")\n","print(\"=\" * 70)"]}]}